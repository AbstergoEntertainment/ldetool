# ldetool means line data extraction tool
Useful for log parsing with Golang.

### Preamble

There's a traditional solution for this kind of tasks: regular expression with capture groups. But it has numerous generic and Go-specific disadvantages:

1. Syntax. Hard to debug and read.
2. Speed. While simple non-capturing regular expressions can be speedy, they quickly becomes slow as the complexity of the regular expression grows
3. They are overpowered. In our experience with log processing we are not looking for patterns within the line. We just need to find some substring, then take everthing between this substring and the next comma as a number, or a string without allocation, just pointing at the fragment extracted from the line. It may cost us additional CPU time to parse and allocate on capture. Not a good thing when we have billions of lines to process.
4. Go regular expressions are slow. Go regular expressions with group capture are even slower. Read basic explanation on performance [here](PERFORMANCE.md)

### Proposal

Look at lines

```
[19234 2017-07-15T15:41:39] FETCH_EVENTS first=1 format=json responseTime=1233 hidden=1 user_agent="Android 7.0.1 App 10.1.0alpha" country=RU /libs/network/fetch_handler.cpp:408
[19234 2017-07-15T15:41:39] FETCH_EVENTS first=0 format=proto responseTime=1233 user_agent="Android 6.0.1 App 9.8.24" country=RU
```

How would we extract all needed data without regexes?
This is a possible way:
* We have the rest of line. What can we do with that, basic operations:
  1. We can look for the some string or character in the rest or in the first N characters in the rest.
  2. We can check if the rest starts with the string or character.
  3. We can pass first N characters
  4. We can take all characters of the rest right to the string or character
  5. We can take the rest of the string
  6. We can take all characters of the rest right to the string of character if it found or take the rest otherwise.
* In practice, we extremely rarely need matched boundary string or character, thus if the string or character matched on operations I, II, IV and VI we pass it and the rest is taken after that match. Obviously, if we took all characters to the end the rest becomes empty.
* There should be a possibility to put subsequences of these operations into optional groups.

#### Syntax for extraction of needed data for these particular lines
See [more details](TOOL_RULES.md) on parsing rules

```perl
Line =
  _ ' '                                  # Pass to the space (x20) character
  Time(string) ']'                       # Take everything as a record for Time right to ']' character
  ^" FETCH_EVENTS "                      # Current rest must starts with " FETCH_EVENTS " string
  ^"first=" First(uint8) ' '             # The rest must starts with "first=" characters, then take the rest until ' ' as uint8
                                         # under the name of First
  ^"format=" Format(string) ' '          # Take format id
  ^"responseTime=" Duration(string) ' '   # Take mandatory response time
  ?Hidden (^"hidden=" Value(uint8) ' ')  # Optionally look for "hidden=\d+"
  ^"user_agent=\"" UserAgent(string) '"' # User agent data
  ^"country=" Country(string) ?? ' ';    # Take data as country to the rest or right to the first space character
```

And what would like to have from it:
* Code must be easy for comprehension and manual extension
* There should be as least dependencies as possible..
* Error messages should be helpful, i.e. mismatch cases must be easy to spot via error messages.
* Extracted data must be accessible via names (using struct fields)
* Unneccessary allocations should be avoided. For instance, when scanning logs we use []byte buffer as a temporary storage. Usually these fields only needed within the lifetime of current line, so extracted substrings better be []byte themselves, not strings

And now use ldetool:
1. Save rule for [Line](#syntax-for-extraction-of-needed-data-for-these-particular-lines) into parsing.scripts file
2. Generate parsing_scripts_lde.go file using
    ```bash
	ldetool generate --package main parsing.scripts
	```
	and move it somewhere. The code will look like
	```go
	package main // We set the package name to main in the call of the utility

	import (
	   ....
        )

	var countryEq = []byte("country=")
	var ....
	....

	// Line autogenerated parser
	type Line struct {
		rest     []byte
		Time     []byte
		First    uint8
		Format   []byte
		Duration []byte
		Hidden   struct {
			Valid bool
			Value uint8
		}
		UserAgent []byte
		Country   []byte
	}

	// Parse autogenerated method of line
	func (p *Line) Parse(line []byte) (bool, error) {
	    ....
	}

	func (p *line) GetHiddenValue() (res uint8) {
		if !p.Hidden.Valid {
			return
		}
		return p.Hidden.Value
	}


    ```

We have done all preparations. Now use generated line parser.

``` go
package main

import (
	"bufio"
	"os"
	"fmt"
)

func main() {
	parser := &Line{}
	reader := bufio.NewReader(os.Stdin)
	scanner := bufio.NewScanner(reader)
	lbuf := &bytes.Buffer{}
	for scanner.Scan() {
		if ok, err := parser.Parse(scanner.Bytes()); !ok {
			continue
		} else if err != nil {
			fmt.Fprintf(os.Stderr, "`\033[1m%s\033[0m` on parsing>>\033[1m%s\033[0m\n", err, scanner.Text())
			continue
		}
		lbuf.Reset()

		fmt.Printf("%s\t%d\t%s\t%s\t%d\t%s\t%s\n",
			string(parser.Time),
			parser.First,
			string(parser.Format),
			string(parser.Duration),
			parser.GetHiddenValue(),
			string(parser.UserAgent),
			string(parser.Country),
		)
	}
}
```
Take care of fmt.Printf usage above. I don't mean it is OK to use fmt.Printf. It is not. All efforts made so far all were for speed purposes, the fmt.Printf basically defeats all of them. You should consider using other tools, that will provide better output performance.
Our typical usecase was to parse lines and put extracted data into clickhouse using [these](https://github.com/sirkon/ch-encode) [tools](https://github.com/sirkon/ch-insert).
